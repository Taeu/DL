{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Boston Housing Dataset\n",
    "\n",
    "이번 과제는 보스턴시의 주택 가격과 관련 데이터를 활용하여 보스턴 시의 집값을 예측하는 문제를 푸는 것입니다. Single-layer Neural Network를 활용하여 보스턴의 집값을 예측하는 알고리즘을 구현하세요.\n",
    "\n",
    "각 컬럼에 대한 설명은 다음과 같습니다. 출처: [ai-times](http://ai-times.tistory.com/431 [ai-times])\n",
    "\n",
    "  * **CRIM**: 자치 시(town) 별 1인당 범죄율\n",
    "  * **ZN**: 25,000 평방피트를 초과하는 거주지역의 비율\n",
    "  * **INDUS**: 비소매상업지역이 점유하고 있는 토지의 비율\n",
    "  * **CHAS**: 찰스강의 경계에 위치해 있으면 1, 그렇지 않으면 0\n",
    "  * **NOX**: 10ppm당 농축 일산화질소\n",
    "  * **RM**: 주택 1가구당 평균 방의 개수\n",
    "  * **AGE**: 1940년 이전에 건축된 소유주택의 비율\n",
    "  * **DIS**: 5개의 보스턴 직업센터까지의 접근성 지수\n",
    "  * **RAD**: 방사형 도로까지의 접근성 지수\n",
    "  * **TAX**: 10,000 달러 당 재산세율\n",
    "  * **PTRATIO**: 자치 시(town)별 학생/교사 비율\n",
    "  * **B**: 1000(Bk-0.63)^2, 여기서 Bk는 자치시별 흑인의 비율을 말함.\n",
    "  * **LSTAT**: 모집단의 하위계층 비율(%)\n",
    "  * **MEDV**: 본인 소유의 주택가격(중앙값) (단위: $1,000)\n",
    "  \n",
    "** 주의 사항 **\n",
    "  * **MEDV**가 label(y), 나머지가 feature(X)라고 가정하고 문제를 풀어주세요.\n",
    "  * **한 번에 너무 잘 풀려는 시도를 하지 마세요.** 처음에는 어떻게든 동작하는 코드를 만드는데 집중하고, 그 다음에 코드를 개성하세요.\n",
    "  * 현실 데이터는 이전에 우리가 다룬 가상의 데이터와 다르기 때문에, error가 0에 가깝게 내려가지 않을 수도 있습니다. (```error = np.abs(y_predict - y).mean()```) **Boston Housing Dataset에서 error는 5 미만으로 내려가면 충분합니다. ** (=$5,000)\n",
    "  * error가 수렴하지 않고 발산한다면, **learning_rate를 작게 조정해보세요**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = boston[\"data\"]\n",
    "\n",
    "print(X.shape)\n",
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = boston[\"target\"]\n",
    "print(y.shape)\n",
    "y[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame(X, columns=boston[\"feature_names\"])\n",
    "data[\"MEDV\"] = y\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "x1 = X[:, 0] # CRIM\n",
    "x2 = X[:, 1] # ZN\n",
    "x3 = X[:, 2] # INDUS\n",
    "x4 = X[:, 3] # CHAS\n",
    "x5 = X[:, 4] # NOX\n",
    "x6 = X[:, 5] # RM\n",
    "x7 = X[:, 6] # AGE\n",
    "x8 = X[:, 7] # DIS\n",
    "x9 = X[:, 8] # RAD\n",
    "x10 = X[:, 9] # TAX\n",
    "x11 = X[:, 10] # PTRATIO\n",
    "x12 = X[:, 11] # B\n",
    "x13 = X[:, 12] # LSTAT\n",
    "print(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = 0.1748\n",
      "error = 0.1531\n",
      "error = 0.1491\n",
      "error = 0.1483\n",
      "error = 0.1481\n",
      "error = 0.1481\n",
      "error = 0.1481\n",
      "error = 0.1481\n",
      "error = 0.1481\n",
      "error = 0.1481\n",
      "w4 =  0.6592266658857049\n",
      "error = 0.1014\n",
      "w5 =  0.3921722629551858\n",
      "error = 0.1239\n",
      "error = 0.0151\n",
      "error = 0.0119\n",
      "error = 0.0119\n",
      "error = 0.0119\n",
      "error = 0.0119\n",
      "error = 0.0119\n",
      "error = 0.0119\n",
      "error = 0.0119\n",
      "error = 0.0119\n",
      "w8 =  0.04313790187891935\n",
      "error = 0.0865\n",
      "error = 0.0062\n",
      "error = 0.0028\n",
      "error = 0.0012\n",
      "error = 0.0006\n",
      "error = 0.0002\n",
      "error = 0.0001\n",
      "w4 = -0.00002, w5 = 0.00766, w8 = 0.00034, bias = 0.65366\n",
      "error = 0.3801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error = 0.3409\n",
      "error = 0.3409\n",
      "error = 0.6591\n",
      "error = 0.6591\n",
      "error = 0.6591\n",
      "error = 0.6591\n",
      "error = 0.3409\n",
      "error = 0.3409\n",
      "error = 0.3409\n",
      "w4 = 0.00203, w5 = 0.03065, w8 = 0.30318, bias = -0.25910\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "\n",
    "# 여기에 Single-layer Neural Network 코드를 작성하여 보스턴 집값 문제를 풀어보세요!\n",
    "def sigmoid(x, derivative=False):\n",
    "\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "\n",
    "y = sigmoid(y)\n",
    "# feature x1 ~ x13, 마지막 bias, label = y\n",
    "w = np.random.uniform(low=-1.0, high=1.0) # 한 feature 에만 \n",
    "num = 10000\n",
    "learning_rate = 0.1\n",
    "# 한개 씩 넣어본결과 상관관계를 가지는 변수는 x4, x5, x8\n",
    "#x4\n",
    "for b in range(num):\n",
    "    \n",
    "    y_pred = sigmoid(w*x4)\n",
    "    error = np.abs(y-y_pred).mean()\n",
    "    if(b%1000== 0) :\n",
    "        print(\"error = {0:4.4f}\".format(error))\n",
    "    if(error < 0.0001) :\n",
    "            break\n",
    "    k = (np.transpose(y_pred-y)*x4).mean()\n",
    "    w= w - k*learning_rate\n",
    "w4 = w\n",
    "print(\"w4 = \", w4)\n",
    "\n",
    "#X4, X5\n",
    "w = np.random.uniform(low=-1.0, high=1.0) # 한 feature 에만 \n",
    "for b in range(num):\n",
    "    \n",
    "    y_pred = sigmoid(w4*x4 + w*x5)\n",
    "    error = np.abs(y-y_pred).mean()\n",
    "    if(b % 1000==0) :\n",
    "        print(\"error = {0:4.4f}\".format(error))\n",
    "    if(error < 0.5) :\n",
    "            break\n",
    "    k = (np.transpose(y_pred-y)*x5).mean()\n",
    "    w= w - k*learning_rate\n",
    "    w4 = w4 - learning_rate * (np.transpose(y_pred-y)*x4).mean()\n",
    "w5 = w\n",
    "print(\"w5 = \", w5)\n",
    "\n",
    "#x4, x5, x8\n",
    "w = np.random.uniform(low=-1.0, high=1.0) # 한 feature 에만 \n",
    "for b in range(num):\n",
    "    \n",
    "    y_pred = sigmoid(w4*x4 + w5*x5 + w*x8)\n",
    "    error = np.abs(y-y_pred).mean()\n",
    "    if(b%1000== 0) :\n",
    "        print(\"error = {0:4.4f}\".format(error))\n",
    "    if(error < 0.0001) :\n",
    "            break\n",
    "    k = (np.transpose(y_pred-y)*x8).mean()\n",
    "    w= w - k*learning_rate\n",
    "    w4 = w4 - learning_rate * (np.transpose(y_pred-y)*x4).mean()\n",
    "    w5 = w5 - learning_rate * (np.transpose(y_pred-y)*x5).mean()\n",
    "w8 = w\n",
    "print(\"w8 = \", w8)\n",
    "\n",
    "#w4, w5, w8\n",
    "bi = np.random.uniform(low=-1.0, high=1.0) # 한 feature 에만 \n",
    "for b in range(100000):\n",
    "    \n",
    "    y_pred = sigmoid(w4*x4 + w5*x5 + w8*x8 +bi)\n",
    "    error = np.abs(y-y_pred).mean()\n",
    "    if(b%10000== 0) :\n",
    "        print(\"error = {0:4.4f}\".format(error))\n",
    "    if(error < 0.0001) :\n",
    "            break\n",
    "    w4 = w4 - learning_rate * (np.transpose(y_pred-y)*x4).mean()\n",
    "    w5 = w5 - learning_rate * (np.transpose(y_pred-y)*x5).mean()\n",
    "    w8 = w8 - learning_rate * (np.transpose(y_pred-y)*x8).mean()\n",
    "    bi = bi - learning_rate * (y_pred-y).mean()\n",
    "print(\"w4 = {0:.5f}, w5 = {1:.5f}, w8 = {2:.5f}, bias = {3:.5f}\".format(w4,w5,w8,bi))\n",
    "\n",
    "# 번외 full model\n",
    "bi = np.random.uniform(low=-1.0, high=1.0) # 한 feature 에만 \n",
    "w1 =np.random.uniform(low=-1.0,high=1.0)\n",
    "w2 =np.random.uniform(low=-1.0,high=1.0)\n",
    "w3 =np.random.uniform(low=-1.0,high=1.0)\n",
    "w6 =np.random.uniform(low=-1.0,high=1.0)\n",
    "w7 =np.random.uniform(low=-1.0,high=1.0)\n",
    "w9 =np.random.uniform(low=-1.0,high=1.0)\n",
    "w10=np.random.uniform(low=-1.0,high=1.0)\n",
    "w11=np.random.uniform(low=-1.0,high=1.0)\n",
    "w12= np.random.uniform(low=-1.0,high=1.0)\n",
    "w13= np.random.uniform(low=-1.0,high=1.0)\n",
    "for b in range(10000):\n",
    "    \n",
    "    y_pred = sigmoid(w1*x1+w2*x2+w3*x3+ w4*x4 + w5*x5 +w6*x6+w7*x7+ w8*x8+w9*x9+w10*x10+w11*x11+w12*x12+w13*x13+bi)\n",
    "    error = np.abs(y-y_pred).mean()\n",
    "    if(b%1000== 0) :\n",
    "        print(\"error = {0:4.4f}\".format(error))\n",
    "    if(error < 0.0001) :\n",
    "            break\n",
    "    w4 = w4 - learning_rate * (np.transpose(y_pred-y)*x4).mean()\n",
    "    w5 = w5 - learning_rate * (np.transpose(y_pred-y)*x5).mean()\n",
    "    w8 = w8 - learning_rate * (np.transpose(y_pred-y)*x8).mean()\n",
    "    bi = bi - learning_rate * (y_pred-y).mean()\n",
    "    w1 = w1 - learning_rate * (np.transpose(y_pred-y)*x1).mean()\n",
    "    w2 = w2 - learning_rate * (np.transpose(y_pred-y)*x2).mean()\n",
    "    w3 = w3 - learning_rate * (np.transpose(y_pred-y)*x3).mean()\n",
    "    w6 = w6 - learning_rate * (np.transpose(y_pred-y)*x6).mean()\n",
    "    w7 = w7 - learning_rate * (np.transpose(y_pred-y)*x7).mean()\n",
    "    w9 = w9 - learning_rate * (np.transpose(y_pred-y)*x9).mean()\n",
    "    w10 = w10 - learning_rate * (np.transpose(y_pred-y)*x10).mean()\n",
    "    w11 = w11 - learning_rate * (np.transpose(y_pred-y)*x11).mean()\n",
    "    w12 = w12 - learning_rate * (np.transpose(y_pred-y)*x12).mean()\n",
    "    w13 = w13 - learning_rate * (np.transpose(y_pred-y)*x13).mean()\n",
    "    \n",
    "print(\"w4 = {0:.5f}, w5 = {1:.5f}, w8 = {2:.5f}, bias = {3:.5f}\".format(w4,w5,w8,bi))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent (use dot product)\n",
    "\n",
    "만일 위의 과제가 너무 쉽다는 생각이 들면, **matrix의 [dot product](https://mathinsight.org/dot_product_matrix_notation)를 활용하여 문제를 풀어보세요.** dot product의 사용법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_temp = np.array([[1, 2, 3],\n",
    "                   [4, 5, 6],\n",
    "                   [7, 8, 9]])\n",
    "\n",
    "print(X_temp.shape)\n",
    "X_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 4, 8])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_temp = np.array([2, 4, 8])\n",
    "\n",
    "print(w_temp.shape)\n",
    "w_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_temp = np.array([0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([  34.1,   76.1,  118.1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = X_temp.dot(w_temp) + b_temp\n",
    "\n",
    "print(y_predict.shape)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13,)\n",
      "w=  [ 0.58981114  0.14606769  0.75291597 -0.03295832  0.25965231  0.75100666\n",
      " -0.4986964   0.40252591 -0.53727779  0.89647304  0.26967735  0.38507541\n",
      "  0.87279557]\n",
      "error = 0.2690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w=  [157.85985435 157.41611091 158.02295919 157.2370849  157.52969552\n",
      " 158.02104987 156.77134682 157.67256912 156.73276543 158.16651625\n",
      " 157.53972057 157.65511862 158.14283878]\n",
      "error = 0.2690\n",
      "w=  [315.12989757 314.68615412 315.2930024  314.50712811 314.79973874\n",
      " 315.29109309 314.04139003 314.94261234 314.00280864 315.43655947\n",
      " 314.80976378 314.92516184 315.412882  ]\n",
      "error = 0.2690\n",
      "w=  [472.39994078 471.95619734 472.56304562 471.77717133 472.06978195\n",
      " 472.5611363  471.31143325 472.21265555 471.27285186 472.70660268\n",
      " 472.079807   472.19520505 472.68292521]\n",
      "error = 0.2690\n",
      "w=  [629.66998399 629.22624055 629.83308883 629.04721454 629.33982517\n",
      " 629.83117952 628.58147646 629.48269877 628.54289507 629.9766459\n",
      " 629.34985021 629.46524827 629.95296843]\n",
      "error = 0.2690\n",
      "w=  [786.94002721 786.49628377 787.10313205 786.31725776 786.60986838\n",
      " 787.10122273 785.85151968 786.75274198 785.81293829 787.24668911\n",
      " 786.61989343 786.73529148 787.22301164]\n",
      "error = 0.2690\n",
      "w=  [944.21007042 943.76632698 944.37317526 943.58730097 943.8799116\n",
      " 944.37126595 943.12156289 944.0227852  943.0829815  944.51673232\n",
      " 943.88993664 944.0053347  944.49305486]\n",
      "error = 0.2690\n",
      "w=  [1101.48011364 1101.0363702  1101.64321847 1100.85734419 1101.14995481\n",
      " 1101.64130916 1100.3916061  1101.29282841 1100.35302472 1101.78677554\n",
      " 1101.15997985 1101.27537791 1101.76309807]\n",
      "error = 0.2690\n",
      "w=  [1258.75015685 1258.30641341 1258.91326169 1258.1273874  1258.41999803\n",
      " 1258.91135238 1257.66164932 1258.56287163 1257.62306793 1259.05681875\n",
      " 1258.43002307 1258.54542113 1259.03314129]\n",
      "error = 0.2690\n",
      "w=  [1416.02020007 1415.57645663 1416.1833049  1415.39743062 1415.69004124\n",
      " 1416.18139559 1414.93169253 1415.83291484 1414.89311114 1416.32686197\n",
      " 1415.70006628 1415.81546434 1416.3031845 ]\n",
      "error = 0.2690\n",
      "w4 =  [1573.29024328 1572.84649984 1573.45334812 1572.66747383 1572.96008445\n",
      " 1573.45143881 1572.20173575 1573.10295806 1572.16315436 1573.59690518\n",
      " 1572.9701095  1573.08550756 1573.57322772]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "# 여기에 Single-layer Neural Network에 dot product를 활용하여 보스턴 집값 문제를 풀어보세요!\n",
    "\n",
    "def sigmoid(x, derivative=False):\n",
    "  return x*(1-x) if derivative else 1/(1+np.exp(-x))\n",
    "\n",
    "# feature x1 ~ x13, 마지막 bias, label = y\n",
    "y = sigmoid(y)\n",
    "w = np.random.uniform(low=-1.0, high=1.0, size=13) # 한 feature 에만 \n",
    "print(w.shape)\n",
    "num = 10000\n",
    "learning_rate = 0.1\n",
    "# 한개 씩 넣어본결과 상관관계를 가지는 변수는 x4, x5, x8\n",
    "#bias도 넣기\n",
    "\n",
    "#x4\n",
    "for b in range(num):\n",
    "    \n",
    "    y_pred = sigmoid(X.dot(w))\n",
    "    error = np.abs(y-y_pred).mean()\n",
    "    if(b%1000== 0) :\n",
    "        print(\"w= \",w)\n",
    "        print(\"error = {0:4.4f}\".format(error))\n",
    "    if(error < 0.0001) :\n",
    "            break\n",
    "    k = (np.transpose(y_pred-y).dot(X)).mean() #X.T.dot()\n",
    "    w= w - k*learning_rate\n",
    "w4 = w\n",
    "print(\"final = \", w4)\n",
    "\n",
    "# 나머지도 똑같이\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
