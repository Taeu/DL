{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-ad2b90f7d3d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# data load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1067\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1837\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1838\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1839\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1840\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1841\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m     \"\"\"\n\u001b[0;32m    779\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data load\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "print(train.shape)\n",
    "train.head()\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "print(test.shape)\n",
    "test.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train[\"label\"].values\n",
    "x_train = train.drop(\"label\",axis=1)\n",
    "x_train = x_train.values\n",
    "xx_train = x_train[0:40000]\n",
    "xx_test = x_train[40000:]\n",
    "yy_train = y_train[0:40000]\n",
    "yy_test = y_train[40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_train.shape\n",
    "xx_train = xx_train.reshape(40000,28,28)\n",
    "\n",
    "xx_test = xx_test.reshape(2000,28,28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 9 7 8 3 4 1 0 9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24d00878eb8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d0217b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24d02163ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.gray()\n",
    "\n",
    "print(yy_test[0:10])\n",
    "\n",
    "figures, axes = plt.subplots(nrows=2, ncols=5)\n",
    "figures.set_size_inches(18, 8)\n",
    "\n",
    "axes[0][0].matshow(xx_test[0])\n",
    "axes[0][1].matshow(xx_test[1])\n",
    "axes[0][2].matshow(xx_test[2])\n",
    "axes[0][3].matshow(xx_test[3])\n",
    "axes[0][4].matshow(xx_test[4])\n",
    "axes[1][0].matshow(xx_test[5])\n",
    "axes[1][1].matshow(xx_test[6])\n",
    "axes[1][2].matshow(xx_test[7])\n",
    "axes[1][3].matshow(xx_test[8])\n",
    "axes[1][4].matshow(xx_test[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_train = xx_train.reshape(40000,28*28)\n",
    "\n",
    "xx_test = xx_test.reshape(2000,28*28)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train, test =  (40000, 784) (2000, 784)\n",
      "y_train, test =  (40000,) (2000,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train, test = ',xx_train.shape,xx_test.shape)\n",
    "print('y_train, test = ',yy_train.shape,yy_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 10) (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "y_train_hot  = to_categorical(yy_train)\n",
    "y_test_hot = to_categorical(yy_test)\n",
    "print(y_train_hot.shape,y_test_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy_train[0:10]\n",
    "y_test_hot[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 2.3024 - acc: 0.1870 - val_loss: 2.3021 - val_acc: 0.1910\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 6s 138us/step - loss: 2.2948 - acc: 0.1773 - val_loss: 2.2695 - val_acc: 0.1570\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 6s 140us/step - loss: 1.9815 - acc: 0.1329 - val_loss: 1.3943 - val_acc: 0.1120\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 6s 142us/step - loss: 1.0611 - acc: 0.1118 - val_loss: 1.0428 - val_acc: 0.1135\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 1.0063 - acc: 0.1133 - val_loss: 1.0281 - val_acc: 0.1140\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 0.9909 - acc: 0.1156 - val_loss: 1.0161 - val_acc: 0.1190\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 6s 138us/step - loss: 0.9820 - acc: 0.1190 - val_loss: 1.0136 - val_acc: 0.1195\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 7s 170us/step - loss: 0.9747 - acc: 0.1223 - val_loss: 1.0061 - val_acc: 0.1210\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 6s 153us/step - loss: 0.9687 - acc: 0.1265 - val_loss: 1.0132 - val_acc: 0.1235\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 6s 144us/step - loss: 0.9665 - acc: 0.1316 - val_loss: 1.0070 - val_acc: 0.1325\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 6s 140us/step - loss: 0.9627 - acc: 0.1367 - val_loss: 0.9937 - val_acc: 0.1385\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 6s 152us/step - loss: 0.9587 - acc: 0.1430 - val_loss: 1.0014 - val_acc: 0.1405\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 6s 154us/step - loss: 0.9557 - acc: 0.1559 - val_loss: 1.0148 - val_acc: 0.1670\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 6s 151us/step - loss: 0.9548 - acc: 0.1646 - val_loss: 1.0033 - val_acc: 0.1640\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 6s 142us/step - loss: 0.9519 - acc: 0.1943 - val_loss: 0.9955 - val_acc: 0.2240\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 8s 190us/step - loss: 0.6303 - acc: 0.6168 - val_loss: 0.4135 - val_acc: 0.8975\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 6s 145us/step - loss: 0.3252 - acc: 0.9078 - val_loss: 0.3933 - val_acc: 0.9015\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 5s 137us/step - loss: 0.3048 - acc: 0.9131 - val_loss: 0.4075 - val_acc: 0.8975\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 6s 139us/step - loss: 0.2994 - acc: 0.9139 - val_loss: 0.4089 - val_acc: 0.8980\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 6s 146us/step - loss: 0.2928 - acc: 0.9176 - val_loss: 0.4002 - val_acc: 0.9020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d010d6828>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=10,\n",
    "                kernel_initializer=RandomUniform(minval=0.0, maxval=0.001),\n",
    "                input_shape=(28 * 28,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "optimizers = SGD(lr=0.00001)\n",
    "model.compile(optimizer=optimizers,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(xx_train,\n",
    "          y_train_hot,\n",
    "          epochs=20,\n",
    "          validation_data=(xx_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 28, 28, 1) (2000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "xx_train = xx_train.reshape(40000, 28, 28, 1)\n",
    "xx_test = xx_test.reshape(2000, 28, 28, 1)\n",
    "\n",
    "print(xx_train.shape, xx_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=6,\n",
    "                 kernel_initializer='random_uniform',\n",
    "                 activation='sigmoid',\n",
    "                 kernel_size=(5, 5),\n",
    "                 input_shape=(28, 28, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(filters=12,\n",
    "                 kernel_initializer='random_uniform',\n",
    "                 activation='sigmoid',\n",
    "                 kernel_size=(5, 5)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                       strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=128,\n",
    "                kernel_initializer='random_uniform',\n",
    "                activation='sigmoid'))\n",
    "model.add(Dense(units=10,\n",
    "                kernel_initializer='random_uniform',\n",
    "                activation='sigmoid'))\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "optimizer = SGD(lr=0.1)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 2000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 2.3040 - acc: 0.1067 - val_loss: 2.3000 - val_acc: 0.1125\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 2.3011 - acc: 0.1116 - val_loss: 2.2984 - val_acc: 0.1125\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 2.2949 - acc: 0.1195 - val_loss: 2.2635 - val_acc: 0.2525\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 1.0066 - acc: 0.7124 - val_loss: 0.4320 - val_acc: 0.8850\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.2883 - acc: 0.9173 - val_loss: 0.2550 - val_acc: 0.9235\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.2050 - acc: 0.9387 - val_loss: 0.1987 - val_acc: 0.9390\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.1636 - acc: 0.9511 - val_loss: 0.1708 - val_acc: 0.9490\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.1391 - acc: 0.9576 - val_loss: 0.1504 - val_acc: 0.9530\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.1198 - acc: 0.9634 - val_loss: 0.1344 - val_acc: 0.9585\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.1084 - acc: 0.9670 - val_loss: 0.1183 - val_acc: 0.9605\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.1017 - acc: 0.9688 - val_loss: 0.1088 - val_acc: 0.9660\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.0926 - acc: 0.9713 - val_loss: 0.1171 - val_acc: 0.9660\n",
      "Epoch 13/100\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.0872 - acc: 0.9734 - val_loss: 0.1042 - val_acc: 0.9665\n",
      "Epoch 14/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0842 - acc: 0.9742 - val_loss: 0.0988 - val_acc: 0.9690\n",
      "Epoch 15/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.0796 - acc: 0.9753 - val_loss: 0.0969 - val_acc: 0.9650\n",
      "Epoch 16/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.0756 - acc: 0.9769 - val_loss: 0.0911 - val_acc: 0.9690\n",
      "Epoch 17/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.0709 - acc: 0.9778 - val_loss: 0.0822 - val_acc: 0.9725\n",
      "Epoch 18/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0682 - acc: 0.9788 - val_loss: 0.0767 - val_acc: 0.9755\n",
      "Epoch 19/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0676 - acc: 0.9794 - val_loss: 0.0722 - val_acc: 0.9770\n",
      "Epoch 20/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0690 - acc: 0.9788 - val_loss: 0.0786 - val_acc: 0.9765\n",
      "Epoch 21/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0665 - acc: 0.9788 - val_loss: 0.0708 - val_acc: 0.9755\n",
      "Epoch 22/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0614 - acc: 0.9806 - val_loss: 0.0737 - val_acc: 0.9790\n",
      "Epoch 23/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0625 - acc: 0.9804 - val_loss: 0.0751 - val_acc: 0.9780\n",
      "Epoch 24/100\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 0.0632 - acc: 0.9807 - val_loss: 0.0698 - val_acc: 0.9790\n",
      "Epoch 25/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0561 - acc: 0.9823 - val_loss: 0.0630 - val_acc: 0.9780\n",
      "Epoch 26/100\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.0558 - acc: 0.9826 - val_loss: 0.0619 - val_acc: 0.9790\n",
      "Epoch 27/100\n",
      "40000/40000 [==============================] - 61s 2ms/step - loss: 0.0544 - acc: 0.9834 - val_loss: 0.0711 - val_acc: 0.9755\n",
      "Epoch 28/100\n",
      "40000/40000 [==============================] - 63s 2ms/step - loss: 0.0513 - acc: 0.9847 - val_loss: 0.0598 - val_acc: 0.9805\n",
      "Epoch 29/100\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 0.0526 - acc: 0.9832 - val_loss: 0.0657 - val_acc: 0.9790\n",
      "Epoch 30/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0540 - acc: 0.9826 - val_loss: 0.0674 - val_acc: 0.9760\n",
      "Epoch 31/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0533 - acc: 0.9839 - val_loss: 0.0591 - val_acc: 0.9810\n",
      "Epoch 32/100\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.0491 - acc: 0.9846 - val_loss: 0.0609 - val_acc: 0.9790\n",
      "Epoch 33/100\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.0476 - acc: 0.9853 - val_loss: 0.0557 - val_acc: 0.9800\n",
      "Epoch 34/100\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.0453 - acc: 0.9860 - val_loss: 0.0587 - val_acc: 0.9830\n",
      "Epoch 35/100\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 0.0427 - acc: 0.9869 - val_loss: 0.0565 - val_acc: 0.9820\n",
      "Epoch 36/100\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.0432 - acc: 0.9861 - val_loss: 0.0589 - val_acc: 0.9765\n",
      "Epoch 37/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0417 - acc: 0.9871 - val_loss: 0.0577 - val_acc: 0.9810\n",
      "Epoch 38/100\n",
      "40000/40000 [==============================] - 58s 1ms/step - loss: 0.0400 - acc: 0.9870 - val_loss: 0.0531 - val_acc: 0.9830\n",
      "Epoch 39/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0423 - acc: 0.9863 - val_loss: 0.0575 - val_acc: 0.9805\n",
      "Epoch 40/100\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.0415 - acc: 0.9869 - val_loss: 0.0515 - val_acc: 0.9800\n",
      "Epoch 41/100\n",
      "40000/40000 [==============================] - 55s 1ms/step - loss: 0.0393 - acc: 0.9876 - val_loss: 0.0508 - val_acc: 0.9795\n",
      "Epoch 42/100\n",
      "40000/40000 [==============================] - 65s 2ms/step - loss: 0.0383 - acc: 0.9877 - val_loss: 0.0485 - val_acc: 0.9840\n",
      "Epoch 43/100\n",
      "40000/40000 [==============================] - 63s 2ms/step - loss: 0.0356 - acc: 0.9892 - val_loss: 0.0505 - val_acc: 0.9835\n",
      "Epoch 44/100\n",
      "40000/40000 [==============================] - 43s 1ms/step - loss: 0.0362 - acc: 0.9888 - val_loss: 0.0466 - val_acc: 0.9840\n",
      "Epoch 45/100\n",
      "40000/40000 [==============================] - 42s 1ms/step - loss: 0.0362 - acc: 0.9887 - val_loss: 0.0493 - val_acc: 0.9825\n",
      "Epoch 46/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0389 - acc: 0.9877 - val_loss: 0.0505 - val_acc: 0.9840\n",
      "Epoch 47/100\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.0359 - acc: 0.9886 - val_loss: 0.0478 - val_acc: 0.9840\n",
      "Epoch 48/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0352 - acc: 0.9889 - val_loss: 0.0504 - val_acc: 0.9860\n",
      "Epoch 49/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0334 - acc: 0.9892 - val_loss: 0.0471 - val_acc: 0.9820\n",
      "Epoch 50/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0338 - acc: 0.9893 - val_loss: 0.0546 - val_acc: 0.9805\n",
      "Epoch 51/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.0335 - acc: 0.9890 - val_loss: 0.0569 - val_acc: 0.9815\n",
      "Epoch 52/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.0316 - acc: 0.9899 - val_loss: 0.0572 - val_acc: 0.9820\n",
      "Epoch 53/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0315 - acc: 0.9903 - val_loss: 0.0548 - val_acc: 0.9835\n",
      "Epoch 54/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0305 - acc: 0.9904 - val_loss: 0.0514 - val_acc: 0.9845\n",
      "Epoch 55/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.0315 - acc: 0.9901 - val_loss: 0.0524 - val_acc: 0.9840\n",
      "Epoch 56/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0311 - acc: 0.9902 - val_loss: 0.0509 - val_acc: 0.9815\n",
      "Epoch 57/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0319 - acc: 0.9901 - val_loss: 0.0520 - val_acc: 0.9830\n",
      "Epoch 58/100\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 0.0323 - acc: 0.9898 - val_loss: 0.0437 - val_acc: 0.9845\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 45s 1ms/step - loss: 0.0314 - acc: 0.9903 - val_loss: 0.0465 - val_acc: 0.9830\n",
      "Epoch 60/100\n",
      "40000/40000 [==============================] - 44s 1ms/step - loss: 0.0306 - acc: 0.9904 - val_loss: 0.0462 - val_acc: 0.9840\n",
      "Epoch 61/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0318 - acc: 0.9903 - val_loss: 0.0475 - val_acc: 0.9835\n",
      "Epoch 62/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0294 - acc: 0.9906 - val_loss: 0.0488 - val_acc: 0.9820\n",
      "Epoch 63/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0298 - acc: 0.9902 - val_loss: 0.0522 - val_acc: 0.9790\n",
      "Epoch 64/100\n",
      "40000/40000 [==============================] - 45s 1ms/step - loss: 0.0318 - acc: 0.9898 - val_loss: 0.0507 - val_acc: 0.9820\n",
      "Epoch 65/100\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.0320 - acc: 0.9896 - val_loss: 0.0478 - val_acc: 0.9825\n",
      "Epoch 66/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0279 - acc: 0.9911 - val_loss: 0.0486 - val_acc: 0.9850\n",
      "Epoch 67/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0273 - acc: 0.9912 - val_loss: 0.0505 - val_acc: 0.9810\n",
      "Epoch 68/100\n",
      "40000/40000 [==============================] - 56s 1ms/step - loss: 0.0307 - acc: 0.9906 - val_loss: 0.0473 - val_acc: 0.9845\n",
      "Epoch 69/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0294 - acc: 0.9911 - val_loss: 0.0527 - val_acc: 0.9820\n",
      "Epoch 70/100\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.0281 - acc: 0.9913 - val_loss: 0.0546 - val_acc: 0.9835\n",
      "Epoch 71/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0278 - acc: 0.9915 - val_loss: 0.0455 - val_acc: 0.9845\n",
      "Epoch 72/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0253 - acc: 0.9923 - val_loss: 0.0524 - val_acc: 0.9810\n",
      "Epoch 73/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0256 - acc: 0.9924 - val_loss: 0.0466 - val_acc: 0.9845\n",
      "Epoch 74/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0241 - acc: 0.9927 - val_loss: 0.0525 - val_acc: 0.9815\n",
      "Epoch 75/100\n",
      "40000/40000 [==============================] - 54s 1ms/step - loss: 0.0257 - acc: 0.9918 - val_loss: 0.0504 - val_acc: 0.9815\n",
      "Epoch 76/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.0248 - acc: 0.9920 - val_loss: 0.0454 - val_acc: 0.9840\n",
      "Epoch 77/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0510 - val_acc: 0.9805\n",
      "Epoch 78/100\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 0.0227 - acc: 0.9931 - val_loss: 0.0527 - val_acc: 0.9805\n",
      "Epoch 79/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0238 - acc: 0.9925 - val_loss: 0.0530 - val_acc: 0.9825\n",
      "Epoch 80/100\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 0.0229 - acc: 0.9930 - val_loss: 0.0446 - val_acc: 0.9840\n",
      "Epoch 81/100\n",
      "40000/40000 [==============================] - 52s 1ms/step - loss: 0.0219 - acc: 0.9934 - val_loss: 0.0507 - val_acc: 0.9815\n",
      "Epoch 82/100\n",
      "40000/40000 [==============================] - 53s 1ms/step - loss: 0.0216 - acc: 0.9936 - val_loss: 0.0422 - val_acc: 0.9845\n",
      "Epoch 83/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.0210 - acc: 0.9939 - val_loss: 0.0478 - val_acc: 0.9845\n",
      "Epoch 84/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.0208 - acc: 0.9940 - val_loss: 0.0427 - val_acc: 0.9840\n",
      "Epoch 85/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0206 - acc: 0.9943 - val_loss: 0.0462 - val_acc: 0.9845\n",
      "Epoch 86/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0221 - acc: 0.9931 - val_loss: 0.0460 - val_acc: 0.9840\n",
      "Epoch 87/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.0228 - acc: 0.9931 - val_loss: 0.0448 - val_acc: 0.9860\n",
      "Epoch 88/100\n",
      "40000/40000 [==============================] - 42s 1ms/step - loss: 0.0218 - acc: 0.9933 - val_loss: 0.0435 - val_acc: 0.9860\n",
      "Epoch 89/100\n",
      "40000/40000 [==============================] - 44s 1ms/step - loss: 0.0202 - acc: 0.9942 - val_loss: 0.0441 - val_acc: 0.9880\n",
      "Epoch 90/100\n",
      "40000/40000 [==============================] - 44s 1ms/step - loss: 0.0197 - acc: 0.9946 - val_loss: 0.0465 - val_acc: 0.9845\n",
      "Epoch 91/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0192 - acc: 0.9943 - val_loss: 0.0422 - val_acc: 0.9850\n",
      "Epoch 92/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0191 - acc: 0.9945 - val_loss: 0.0407 - val_acc: 0.9865\n",
      "Epoch 93/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0182 - acc: 0.9946 - val_loss: 0.0422 - val_acc: 0.9855\n",
      "Epoch 94/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.0193 - acc: 0.9943 - val_loss: 0.0426 - val_acc: 0.9845\n",
      "Epoch 95/100\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0422 - val_acc: 0.9870\n",
      "Epoch 96/100\n",
      "40000/40000 [==============================] - 58s 1ms/step - loss: 0.0191 - acc: 0.9942 - val_loss: 0.0423 - val_acc: 0.9840\n",
      "Epoch 97/100\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.0184 - acc: 0.9945 - val_loss: 0.0417 - val_acc: 0.9870\n",
      "Epoch 98/100\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.0201 - acc: 0.9937 - val_loss: 0.0420 - val_acc: 0.9825\n",
      "Epoch 99/100\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.0203 - acc: 0.9937 - val_loss: 0.0442 - val_acc: 0.9850\n",
      "Epoch 100/100\n",
      "40000/40000 [==============================] - 47s 1ms/step - loss: 0.0196 - acc: 0.9940 - val_loss: 0.0430 - val_acc: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d0187c550>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xx_train,\n",
    "          y_train_hot,\n",
    "          epochs=100,\n",
    "#           epochs=30,\n",
    "          validation_data=(xx_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.989000\n"
     ]
    }
   ],
   "source": [
    "#prediction code\n",
    "\n",
    "predictions = model.predict(xx_test)\n",
    "\n",
    "predictions = np.argmax(predictions, axis=1)\n",
    "result = pd.DataFrame({'actual': yy_test, 'predict': predictions})\n",
    "\n",
    "accuracy = (result['actual'] == result['predict']).mean()\n",
    "print(\"Accuracy = {0:.6f}\".format(accuracy))\n",
    "      \n",
    "result.head(10)\n",
    "\n",
    "#for submission\n",
    "x_test = test.values\n",
    "x_test = x_test.reshape(28000, 28, 28, 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_test.shape)\n",
    "\n",
    "predictions_test = model.predict(x_test)\n",
    "predictions_test = np.argmax(predictions_test, axis=1)\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0      2\n",
      "1      0\n",
      "2      9\n",
      "3      9\n",
      "4      3\n",
      "5      7\n",
      "6      0\n",
      "7      3\n",
      "8      0\n",
      "9      3\n",
      "10     5\n",
      "11     7\n",
      "12     4\n",
      "13     0\n",
      "14     4\n",
      "15     3\n",
      "16     3\n",
      "17     1\n",
      "18     9\n",
      "19     0\n",
      "20     9\n",
      "21     1\n",
      "22     1\n",
      "23     5\n",
      "24     7\n",
      "25     4\n",
      "26     2\n",
      "27     7\n",
      "28     4\n",
      "29     7\n",
      "...   ..\n",
      "27970  5\n",
      "27971  0\n",
      "27972  4\n",
      "27973  8\n",
      "27974  0\n",
      "27975  3\n",
      "27976  6\n",
      "27977  0\n",
      "27978  1\n",
      "27979  9\n",
      "27980  3\n",
      "27981  1\n",
      "27982  1\n",
      "27983  0\n",
      "27984  4\n",
      "27985  5\n",
      "27986  2\n",
      "27987  2\n",
      "27988  9\n",
      "27989  6\n",
      "27990  7\n",
      "27991  6\n",
      "27992  1\n",
      "27993  9\n",
      "27994  7\n",
      "27995  9\n",
      "27996  7\n",
      "27997  3\n",
      "27998  9\n",
      "27999  2\n",
      "\n",
      "[28000 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions_test\n",
    "pr = pd.DataFrame(predictions_test)\n",
    "print(pr)\n",
    "pr.to_csv('sample_submission.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-98-a03b41d773d6>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-98-a03b41d773d6>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    for x in\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "with open('sample_submission.csv', 'w') as csvfile:\n",
    "    fieldnames = ['ImageId', 'Label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "    for x in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Genalized Fuction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_function(mod_name, model_name):\n",
    "    y_pred = model_train_predict(mod_name, model_name)\n",
    "    output_prediction(y_pred, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def model_train_predict(mod_name, model_name):\n",
    "    import_mod = __import__(mod_name, fromlist = str(True))\n",
    "    if hasattr(import_mod, model_name):\n",
    "         f = getattr(import_mod, model_name)\n",
    "    else:\n",
    "        print(\"404\")\n",
    "        return []\n",
    "    clf = f()\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_train)\n",
    "    get_acc(y_pred, y_train)\n",
    "    scores = cross_val_score(clf, x_train, y_train, cv=5)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    y_pred = clf.predict(x_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(y_pred, y_train):\n",
    "    right_num = (y_train == y_pred).sum()\n",
    "    print(\"acc: \", right_num/n_samples_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_prediction(y_pred, model_name):\n",
    "    print(y_pred)\n",
    "    data_predict = {\"ImageId\":range(1, n_samples_test+1), \"Label\":y_pred}\n",
    "    data_predict = pd.DataFrame(data_predict)\n",
    "    data_predict.to_csv(\"dr output %s.csv\" %model_name, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras learn .\n",
    "from keras.datasets import mnist\n",
    "\n",
    "((X_train, y_train), (X_test, y_test)) = mnist.load_data()\n",
    " \n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "X_train = X_train.reshape(60000, 28 * 28)\n",
    "X_test = X_test.reshape(10000, 28 * 28)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# One hot encoding .\n",
    "# np.eye(10)[y_train] .\n",
    "y_train_hot = to_categorical(y_train)\n",
    "\n",
    "# np.eye(10)[y_test] .\n",
    "y_test_hot = to_categorical(y_test)\n",
    "\n",
    "print(y_train_hot.shape, y_test_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Reshape, Conv2D, AveragePooling2D, Flatten\n",
    "from keras.optimizers import adam\n",
    "\n",
    "model_name = \"CNN\"\n",
    "model = Sequential()\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "\n",
    "model.add(Reshape(target_shape=(1, 28, 28), input_shape=(784,)))\n",
    "model.add(Conv2D(kernel_size=(3, 3), filters=32, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\", use_bias=False))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "model.add(Conv2D(kernel_size=(3, 3), filters=64, padding=\"same\", data_format=\"channels_first\", kernel_initializer=\"uniform\", use_bias=False))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2), data_format=\"channels_first\"))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(output_dim=1000, activation='relu'))\n",
    "model.add(Dense(output_dim=100, activation='relu'))\n",
    "model.add(Dense(output_dim=10, activation='softmax'))\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=40, batch_size=64)\n",
    "y_pred = model.predict_classes(x_test)\n",
    "\n",
    "output_prediction(y_pred, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
