{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 안녕하세요. 정원석 입니다. \n",
    "\n",
    "## 지금부터 \"밑바닥부터 만들어보는 핸드메이드 인공지능 실습\"을 하겠습니다. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![6_28 001](https://user-images.githubusercontent.com/11300712/41980009-4aa7f43a-79da-11e8-91ec-8c485c6e7ef8.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 OpenAI의 gym을 설명할게요. \n",
    "\n",
    "참고 링크 : \n",
    "OpenAI : \n",
    "https://gym.openai.com/\n",
    "\n",
    "OpenAi Environment : \n",
    "\n",
    "https://gym.openai.com/envs/#classic_control\n",
    "\n",
    "OpenAi gym 사용법\n",
    "\n",
    "https://wonseokjung.github.io//reinforcementlearning/update/openai-gym/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 강화학습과 친해지기 위한 OpenAI의 Gym사용법\n",
    "\n",
    "강화학습을 공부해보신 분들은 Gym이라는 용어를 많이 들어보셨을 것이다. \n",
    "\n",
    "체육관의 의미를 가진 Gym은 무엇이며, 강화학습에 어떻게 사용될까?\n",
    "\n",
    "\n",
    "\n",
    "먼저 Gym은 OpenAI라는 회사에서 만들었다.\n",
    "\n",
    "Gym을 만든 OpenAI는 비영리 인공지능 연구소이며, 안전한 인공지능을 만드는 것이 목표라고 한다. \n",
    "\n",
    "\n",
    "OpenAI는 Gym과 Baselines라는 라이브러리를 제공한다. \n",
    "\n",
    "Gym은 Reinforcement Learning Algorithms을 개발하고 비교하기 위한 툴킷 이고,\n",
    "\n",
    "algorithm을 실험해 볼 수 있도록 여러가지 Environments을 제공한다. \t\n",
    "\n",
    "\n",
    "[Gym 환경모음 링크](http://gym.openai.com)\n",
    "\n",
    "[Gym  webistie 링크](http://GYM.OPENAI.COM)\n",
    "\n",
    "Baselines는 강화학습 알고리즘 모음이다. \n",
    "\n",
    "OpenAI는 강화학습을 실험해볼 수 있도록, gym과 Baselines같은 강화학습 환경과 알고리즘을 제공한다. \n",
    "\n",
    "\n",
    "\n",
    "[Baselines 깃허브 링크](https://github.com/openai/baselines)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. gym 설치하기\n",
    "`pip3 install gym`\n",
    "\n",
    "gym을 설치하기 위해 python 3.5이상 버전에서 pip3 명령어로 gym을 설치한다. \n",
    "\n",
    "또는\n",
    "\n",
    "git clone을 하여 설치한다. \n",
    "\n",
    "```\n",
    "git clone https://github.com/openai/gym\n",
    "cd gym\n",
    "pip3 install -e .\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Environments\n",
    "\n",
    "Algorithm을 환경에 적용해 보기전에, \n",
    "\n",
    "Cartpole이란 게임을 gym라이브러리를 통해 불러와서 action을 선택해보도록 하겠다. \n",
    "\n",
    "a. 함수 설명\n",
    "\n",
    "`gym.make()` : 강화학습 환경을 불러온다.  \n",
    "\n",
    "`env.reset()` : 환경을 초기화 한다. \n",
    "\n",
    "`env.render()` : 화면을 출력한다.\n",
    "\n",
    "`env.action_space.sample()` : 임의의 action을 선택 \n",
    "\n",
    "`env.step` : 선택한 action을 환경으로 보낸다.\n",
    "\n",
    "```\n",
    "import gym\n",
    "\n",
    "env=gym.make('CartPole-V0')\n",
    "\n",
    "env.reset()\n",
    "\n",
    "for i in range(1000):\n",
    "\tenv.render()\n",
    "    \tenv.step(env.action_space.sample())\n",
    "\n",
    "```\n",
    "\n",
    "위와같은 python코드로, \n",
    "\n",
    "gym을 통하여 카트폴 환경을 부르고, action을 선택하며 화면에 표시를 할수 있다.\n",
    "\n",
    "다른 환경을 불러오기를 원하면 `gym.make('CartPole-V0')` 대신에 [Gym 환경모음 링크](http://gym.openai.com) 에서 원하시는 환경을 선택하면 된다.\n",
    "\n",
    "- - -\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Observations\n",
    "\n",
    "위의 예는 env.action_space.sample()을 통하여 임의의 action을 선택하였다.\n",
    "\n",
    "이렇게 임의의 action을 선택하지 않고 더 좋은 action을 선택하려면, \n",
    "\n",
    "우리가 선택한 action이 환경에 어떻게 작용하는지 알면 좋을것이다. \n",
    "\n",
    "이 기능한 하는 함수는 위에서 본 `step`함수이다. \n",
    "\n",
    "이 선택한 action을 `step`함수로 보내면, 다음의 4가지 value를 return한다. \n",
    "\n",
    "* observation : 픽셀 데이터과 같은 관찰값\n",
    "\n",
    "* reward : 그 action을 하므로서 환경에서 받는 reward값\n",
    "\n",
    "* done : 에피소드가 terminal 되면 True( 목표를 달성했거나, 에이전트가 목숨을 잃었을때)\n",
    "\n",
    "* info : 환경의 정보들( 점수 등등 ) \n",
    "\n",
    "\n",
    "Agent는 각 time step마다 action을 선택하며 Environment과 상호작용을 한다. \n",
    "\n",
    "이때 Environment는 Agent로부터 action을 받고 reward와 observation을 return 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 카트폴 환경 불러서 random action 선택하여 환경과 상호작용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env=gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-e0b1b108ea0e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-15-e0b1b108ea0e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    export DISPLAY=':99.0'\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "export DISPLAY=':99.0'\n",
    "Xvfb :99 -screen 0 1400x900x24 > /dev/null 2>&1 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method Viewer.__del__ of <gym.envs.classic_control.rendering.Viewer object at 0x000002082D071C88>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 143, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 62, in close\n",
      "    self.window.close()\n",
      "AttributeError: 'Viewer' object has no attribute 'window'\n",
      "Exception ignored in: <bound method Viewer.__del__ of <gym.envs.classic_control.rendering.Viewer object at 0x000002082D077B38>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 143, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 62, in close\n",
      "    self.window.close()\n",
      "AttributeError: 'Viewer' object has no attribute 'window'\n",
      "Exception ignored in: <bound method Viewer.__del__ of <gym.envs.classic_control.rendering.Viewer object at 0x000002082D078B00>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 143, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 62, in close\n",
      "    self.window.close()\n",
      "AttributeError: 'Viewer' object has no attribute 'window'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(20):\n",
    "    observation=env.reset()\n",
    "    for t in range(100):\n",
    "        ##env.render()\n",
    "        \n",
    "        action= env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경을 바꿔볼까요? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gym.openai.com/envs/#classic_control\n",
    "\n",
    "\n",
    "위의 링크에서 원하는 환경을 선택하세요 :) \n",
    "\n",
    "저는 MountainCarContinuous-v0라는 환경을 사용해볼게요. \n",
    "\n",
    "\n",
    "# 만약 Atari 환경을 원하시면 \n",
    "\n",
    "## MAC\n",
    "\n",
    "$ pip3 install Pillow\n",
    "\n",
    "$ pip3 install numpy\n",
    "\n",
    "$ pip3 install torch=='0.3.1'\n",
    "\n",
    "\n",
    "$ pip3 install matplotlib\n",
    "\n",
    "$ pip3 install h5py\n",
    "\n",
    "$ pip3 install gym\n",
    "\n",
    "$ pip3 install gym[atari]\n",
    "\n",
    "$ pip3 install -U scikit-learn\n",
    "\n",
    "## Window\n",
    "\n",
    "![screen shot 2018-06-26 at 21 17 55](https://user-images.githubusercontent.com/11300712/41952789-9c54b948-7986-11e8-8ac0-8e130331e4c1.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env=gym.make(\"MountainCarContinuous-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.44835125,  0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "abstract",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-d9761596d5d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\continuous_mountain_car.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_position\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_position\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_height\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, width, height, display)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow_closed_by_user\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyglet\\window\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mscreen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_screen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyglet\\canvas\\base.py\u001b[0m in \u001b[0;36mget_default_screen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mScreen\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         '''\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_screens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyglet\\canvas\\base.py\u001b[0m in \u001b[0;36mget_screens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mScreen\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         '''\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'abstract'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_default_screen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: abstract"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method Viewer.__del__ of <gym.envs.classic_control.rendering.Viewer object at 0x000002082D077F60>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 143, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 62, in close\n",
      "    self.window.close()\n",
      "AttributeError: 'Viewer' object has no attribute 'window'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.45019948, -0.00184823]), -0.0738062512037633, False, {})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    ##env.render()\n",
    "    action= env.action_space.sample()\n",
    "    \n",
    "    observation, reward, done, info = env.step(action)\n",
    "    \n",
    "    if i==100:\n",
    "        break\n",
    "        \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  DQN을 사용하여 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![screen shot 2018-06-27 at 07 10 01](https://user-images.githubusercontent.com/11300712/41979814-cbc4ecea-79d9-11e8-8f1b-7e197575cd07.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method Viewer.__del__ of <gym.envs.classic_control.rendering.Viewer object at 0x000002082CA124E0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 143, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 62, in close\n",
      "    self.window.close()\n",
      "AttributeError: 'Viewer' object has no attribute 'window'\n",
      "Exception ignored in: <bound method Viewer.__del__ of <gym.envs.classic_control.rendering.Viewer object at 0x000002082D083828>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 143, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\", line 62, in close\n",
      "    self.window.close()\n",
      "AttributeError: 'Viewer' object has no attribute 'window'\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Use Cuda</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replay Buffer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state      = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cart Pole Environment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "env=gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Epsilon greedy exploration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_start = 1.0\n",
    "epsilon_final = 0.01\n",
    "epsilon_decay = 500\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2082e38d438>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2082e2f6160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([epsilon_by_frame(i) for i in range(10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Deep Q Network</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(env.observation_space.shape[0], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, env.action_space.n)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state   = Variable(torch.FloatTensor(state).unsqueeze(0), volatile=True)\n",
    "            q_value = self.forward(state)\n",
    "            action  = q_value.max(1)[1].data[0]\n",
    "        else:\n",
    "            action = random.randrange(env.action_space.n)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN(env.observation_space.shape[0], env.action_space.n)\n",
    "\n",
    "if USE_CUDA:\n",
    "    model = model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "replay_buffer = ReplayBuffer(1000) ## replay buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computing Temporal Difference Loss</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
    "    action     = Variable(torch.LongTensor(action))\n",
    "    reward     = Variable(torch.FloatTensor(reward))\n",
    "    done       = Variable(torch.FloatTensor(done))\n",
    "\n",
    "    q_values      = model(state)\n",
    "    next_q_values = model(next_state)\n",
    "\n",
    "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value     = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    \n",
    "    loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "abstract",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-ddc76697a09a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mframe_idx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_frames\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mepsilon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepsilon_by_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[1;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassic_control\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviewer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrendering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mViewer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcartwidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcartwidth\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcartheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m             \u001b[0maxleoffset\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mcartheight\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gym\\envs\\classic_control\\rendering.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, width, height, display)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyglet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwindow_closed_by_user\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misopen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyglet\\window\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, width, height, caption, resizable, style, fullscreen, visible, vsync, display, screen, config, context, mode)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m             \u001b[0mscreen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_screen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyglet\\canvas\\base.py\u001b[0m in \u001b[0;36mget_default_screen\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mScreen\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m         '''\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_screens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyglet\\canvas\\base.py\u001b[0m in \u001b[0;36mget_screens\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;32mclass\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mScreen\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         '''\n\u001b[1;32m---> 65\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'abstract'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_default_screen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: abstract"
     ]
    }
   ],
   "source": [
    "num_frames = 10000\n",
    "batch_size = 32\n",
    "gamma      = 0.99\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset()\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    env.render()\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    action = model.act(state, epsilon)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        \n",
    "    if len(replay_buffer) > batch_size:\n",
    "        loss = compute_td_loss(batch_size)\n",
    "        losses.append(loss.data[0])\n",
    "        \n",
    "    if frame_idx % 200 == 0:\n",
    "        plot(frame_idx, all_rewards, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://github.com/wonseokjung\n",
    "\n",
    "https://wonseokjung.github.io/\n",
    "\n",
    "https://github.com/higgsfield/RL-Adventure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><hr></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
